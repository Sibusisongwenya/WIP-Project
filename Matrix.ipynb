{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "authorship_tag": "ABX9TyPhkXXUF6CYcIiLCdCEh6qz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sibusisongwenya/WIP-Project/blob/main/Matrix.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "OOPK9y7yjtGz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5ef63af-498f-43c7-d9ec-6e3aa6283409"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "# Append the project root to the Python path\n",
        "sys.path.append('/content/drive/MyDrive/uc')\n",
        "!pip install torchbnn\n",
        "os.chdir(\"/content/drive/MyDrive/uc\")\n",
        "print(\"Current working directory:\", os.getcwd())"
      ],
      "metadata": {
        "id": "rnWisKKAjs28",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15448e80-c8cb-4f78-975a-8052725a01be"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchbnn in /usr/local/lib/python3.11/dist-packages (1.2)\n",
            "Current working directory: /content/drive/MyDrive/uc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import time\n",
        "import random\n",
        "import logging\n",
        "import argparse\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "from torchvision import transforms, models\n",
        "\n",
        "# Import modules from our project\n",
        "from dataset.ucmayo4 import UCMayo4\n",
        "from utils.discretize import (discretize_to_four_class, discretize_binary, entropy_confidence, ci_confidence,\n",
        "                              uncertainty_degree, probability_based_confidence)\n",
        "from utils.magic import BayesianDenseNet121_LLSVI, DenseNet121_LLDropout, load_bayesian_model, load_mc_dropout_model\n",
        "from utils.evaluation import evaluate_deterministic_model, evaluate_bayesian_model, calculate_uce\n",
        "from utils.reporting import generate_clinical_report, generate_patient_case_studies\n",
        "from utils.plotting import (\n",
        "    plot_regression_uncertainty,\n",
        "    plot_calibration_histograms,\n",
        "    plot_uncertainty_histogram,\n",
        "    plot_uncertainty_vs_error,\n",
        "    plot_confusion_matrix,\n",
        "    plot_reliability_diagram\n",
        ")\n",
        "\n",
        "# Configure logging (log to console and file \"my_logs.log\")\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
        "    handlers=[logging.StreamHandler(), logging.FileHandler(\"my_logs.log\")]\n",
        ")\n",
        "logging.info(\"Test log: Logging is configured!\")\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "RANDOM_SEED = 35\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "np.random.seed(RANDOM_SEED)\n",
        "random.seed(RANDOM_SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(RANDOM_SEED)\n",
        "\n",
        "def create_transform(resize: int, normalize: bool, augment: bool):\n",
        "    transform_list = [transforms.Resize((resize, resize))]\n",
        "    if augment:\n",
        "        transform_list.extend([transforms.RandomHorizontalFlip(), transforms.RandomRotation(20)])\n",
        "    transform_list.append(transforms.ToTensor())\n",
        "    if normalize:\n",
        "        transform_list.append(transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                                    std=[0.229, 0.224, 0.225]))\n",
        "    return transforms.Compose(transform_list)\n",
        "\n",
        "def parse_arguments():\n",
        "    parser = argparse.ArgumentParser(description=\"Mayo Score Prediction with Uncertainty\")\n",
        "    parser.add_argument(\"--train_dir\", type=str, required=True, help=\"Path to training data\")\n",
        "    parser.add_argument(\"--calibration_dir\", type=str, required=True, help=\"Path to calibration data\")\n",
        "    parser.add_argument(\"--test_dir\", type=str, required=True, help=\"Path to test data\")\n",
        "    parser.add_argument(\"--checkpoint\", type=str, required=True, help=\"Path to model checkpoint\")\n",
        "    parser.add_argument(\"--dropout_rate\", type=float, default=0.3, help=\"Dropout rate\")\n",
        "    parser.add_argument(\"--num_mc_samples\", type=int, default=50, help=\"Number of Monte Carlo samples\")\n",
        "    parser.add_argument(\"--batch_size\", type=int, default=32, help=\"Batch size\")\n",
        "\n",
        "    # For Colab, override command-line arguments:\n",
        "    if 'ipykernel' in sys.modules:\n",
        "        args = parser.parse_args([\n",
        "            \"--train_dir\", \"/content/drive/MyDrive/uc/test_set/train\",\n",
        "            \"--calibration_dir\", \"/content/drive/MyDrive/uc/test_set/calibration\",\n",
        "            \"--test_dir\", \"/content/drive/MyDrive/uc/test_set/test\",\n",
        "            \"--checkpoint\", \"/content/drive/MyDrive/uc/weights/best_DenseNet121.pth.tar\",\n",
        "            \"--dropout_rate\", \"0.2\",\n",
        "            \"--num_mc_samples\", \"50\",\n",
        "            \"--batch_size\", \"64\"\n",
        "        ])\n",
        "    else:\n",
        "        args = parser.parse_args()\n",
        "    return args\n",
        "\n",
        "def load_dataloaders(args):\n",
        "    train_transform = create_transform(256, True, True)\n",
        "    val_transform = create_transform(256, True, False)\n",
        "    test_transform = val_transform\n",
        "    train_dataset = UCMayo4(root_dir=args.train_dir, transform=train_transform)\n",
        "    val_dataset = UCMayo4(root_dir=args.calibration_dir, transform=val_transform)\n",
        "    test_dataset = UCMayo4(root_dir=args.test_dir, transform=test_transform)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=args.batch_size, shuffle=False)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=args.batch_size, shuffle=False)\n",
        "    return train_loader, val_loader, test_loader\n",
        "\n",
        "def main():\n",
        "    args = parse_arguments()\n",
        "    logging.info(\"Arguments parsed successfully.\")\n",
        "    logging.info(f\"Current working directory: {os.getcwd()}\")\n",
        "\n",
        "    train_loader, val_loader, test_loader = load_dataloaders(args)\n",
        "    logging.info(f\"DataLoaders loaded. (Train: {len(train_loader)} batches, Val: {len(val_loader)} batches, Test: {len(test_loader)} batches)\")\n",
        "\n",
        "    # Instantiate and load models using functions from magic.py\n",
        "    bayesian_model_instance = load_bayesian_model(args.checkpoint, DEVICE, pretrained=True)\n",
        "    dropout_model_instance = load_mc_dropout_model(args.checkpoint, DEVICE, pretrained=True, dropout_prob=args.dropout_rate)\n",
        "\n",
        "    # Forward pass demonstration with dummy input (MC sampling enabled via sample=True)\n",
        "    dummy_input = torch.randn(1, 3, 256, 256).to(DEVICE)\n",
        "    bayesian_output = bayesian_model_instance(dummy_input, sample=True)\n",
        "    dropout_output = dropout_model_instance(dummy_input, sample=True)\n",
        "    logging.info(f\"MC-Sampling output (Bayesian): {bayesian_output}\")\n",
        "    logging.info(f\"MC-Sampling output (Dropout): {dropout_output}\")\n",
        "\n",
        "    # Evaluate models (example calls; further evaluation and reporting follow)\n",
        "    deterministic_results = evaluate_deterministic_model(bayesian_model_instance, test_loader, DEVICE)\n",
        "    bayesian_llsvi_results = evaluate_bayesian_model(\n",
        "        bayesian_model_instance,\n",
        "        test_loader,\n",
        "        num_samples=args.num_mc_samples,\n",
        "        probability_method='cdf',\n",
        "        device=DEVICE,\n",
        "        sub_batch_size=8\n",
        "    )\n",
        "    bayesian_lldropout_results = evaluate_bayesian_model(\n",
        "        dropout_model_instance,\n",
        "        test_loader,\n",
        "        num_samples=args.num_mc_samples,\n",
        "        probability_method='cdf',\n",
        "        device=DEVICE,\n",
        "        sub_batch_size=8\n",
        "    )\n",
        "\n",
        "    # Compute regression error metrics (continuous predictions vs. ground truth)\n",
        "    det_cont_preds = deterministic_results['continuous_predictions']\n",
        "    det_labels = deterministic_results['labels']\n",
        "    det_mae = np.mean(np.abs(det_cont_preds - det_labels))\n",
        "    det_rmse = np.sqrt(np.mean((det_cont_preds - det_labels) ** 2))\n",
        "\n",
        "    bay_llsvi_cont_preds = bayesian_llsvi_results['continuous_predictions']\n",
        "    bay_llsvi_mae = np.mean(np.abs(bay_llsvi_cont_preds - det_labels))\n",
        "    bay_llsvi_rmse = np.sqrt(np.mean((bay_llsvi_cont_preds - det_labels) ** 2))\n",
        "\n",
        "    bay_lldrop_cont_preds = bayesian_lldropout_results['continuous_predictions']\n",
        "    bay_lldrop_mae = np.mean(np.abs(bay_lldrop_cont_preds - det_labels))\n",
        "    bay_lldrop_rmse = np.sqrt(np.mean((bay_lldrop_cont_preds - det_labels) ** 2))\n",
        "\n",
        "    # Compute binary classification metrics\n",
        "    from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
        "    det_bin_preds = deterministic_results['binary_predictions']\n",
        "    det_accuracy = accuracy_score(det_labels, det_bin_preds)\n",
        "    det_f1 = f1_score(det_labels, det_bin_preds, average='weighted')\n",
        "    try:\n",
        "        det_auc = roc_auc_score(det_labels, det_bin_preds)\n",
        "    except ValueError:  # Catch ValueError for single-class cases\n",
        "        det_auc = 0  # Set to 0 when only one class is present\n",
        "\n",
        "    bay_llsvi_bin_preds = bayesian_llsvi_results['binary_predictions']\n",
        "    bay_llsvi_accuracy = accuracy_score(det_labels, bay_llsvi_bin_preds)\n",
        "    bay_llsvi_f1 = f1_score(det_labels, bay_llsvi_bin_preds, average='weighted')\n",
        "    try:\n",
        "        bay_llsvi_auc = roc_auc_score(det_labels, bay_llsvi_bin_preds)\n",
        "    except ValueError:  # Catch ValueError for single-class cases\n",
        "        bay_llsvi_auc = 0  # Set to 0 when only one class is present\n",
        "\n",
        "    bay_lldrop_bin_preds = bayesian_lldropout_results['binary_predictions']\n",
        "    bay_lldrop_accuracy = accuracy_score(det_labels, bay_lldrop_bin_preds)\n",
        "    bay_lldrop_f1 = f1_score(det_labels, bay_lldrop_bin_preds, average='weighted')\n",
        "    try:\n",
        "        bay_lldrop_auc = roc_auc_score(det_labels, bay_lldrop_bin_preds)\n",
        "    except ValueError:  # Catch ValueError for single-class cases\n",
        "        bay_lldrop_auc = 0  # Set to 0 when only one class is present\n",
        "\n",
        "\n",
        "    # Compute Confidence/Uncertainty Metrics using computed values\n",
        "    det_probs = np.array(deterministic_results.get('probabilities', np.eye(4)[det_bin_preds]))\n",
        "    det_prob_conf = probability_based_confidence(det_probs)\n",
        "    det_entropy_conf = np.mean(entropy_confidence(det_probs))\n",
        "    det_ci_conf = np.mean(ci_confidence(np.array(deterministic_results['uncertainties'])))\n",
        "    det_uc = np.mean(uncertainty_degree(det_probs))\n",
        "    det_uce, _ = calculate_uce(det_labels, det_cont_preds, deterministic_results['uncertainties'])\n",
        "\n",
        "    bay_llsvi_probs = np.array(bayesian_llsvi_results.get('cdf_probs'))\n",
        "    bay_llsvi_prob_conf = probability_based_confidence(bay_llsvi_probs)\n",
        "    bay_llsvi_entropy_conf = np.mean(entropy_confidence(bay_llsvi_probs))\n",
        "    bay_llsvi_ci_conf = np.mean(ci_confidence(np.array(bayesian_llsvi_results['uncertainties'])))\n",
        "    bay_llsvi_uc = np.mean(uncertainty_degree(bay_llsvi_probs))\n",
        "    bay_llsvi_uce, _ = calculate_uce(bayesian_llsvi_results['labels'], bay_llsvi_cont_preds, bayesian_llsvi_results['uncertainties'])\n",
        "\n",
        "    bay_lldrop_probs = np.array(bayesian_lldropout_results.get('cdf_probs'))\n",
        "    bay_lldrop_prob_conf = probability_based_confidence(bay_lldrop_probs)\n",
        "    bay_lldrop_entropy_conf = np.mean(entropy_confidence(bay_lldrop_probs))\n",
        "    bay_lldrop_ci_conf = np.mean(ci_confidence(np.array(bayesian_lldropout_results['uncertainties'])))\n",
        "    bay_lldrop_uc = np.mean(uncertainty_degree(bay_lldrop_probs))\n",
        "    bay_lldrop_uce, _ = calculate_uce(bayesian_lldropout_results['labels'], bay_lldrop_cont_preds, bayesian_lldropout_results['uncertainties'])\n",
        "\n",
        "    # Build overall metrics dictionary\n",
        "    overall_metrics = {\n",
        "        \"Deterministic\": {\n",
        "            \"accuracy\": det_accuracy,\n",
        "            \"auc\": det_auc,\n",
        "            \"binary_accuracy\": det_accuracy,\n",
        "            \"f1\": det_f1,\n",
        "            \"mae\": det_mae,\n",
        "            \"rmse\": det_rmse,\n",
        "            \"prob_conf\": det_prob_conf,\n",
        "            \"entropy_conf\": det_entropy_conf,\n",
        "            \"ci_conf\": det_ci_conf,\n",
        "            \"uc\": det_uc,\n",
        "            \"uce\": det_uce\n",
        "        },\n",
        "        \"Bayesian LL-SVI\": {\n",
        "            \"accuracy\": bay_llsvi_accuracy,\n",
        "            \"auc\": bay_llsvi_auc,\n",
        "            \"binary_accuracy\": bay_llsvi_accuracy,\n",
        "            \"f1\": bay_llsvi_f1,\n",
        "            \"mae\": bay_llsvi_mae,\n",
        "            \"rmse\": bay_llsvi_rmse,\n",
        "            \"prob_conf\": bay_llsvi_prob_conf,\n",
        "            \"entropy_conf\": bay_llsvi_entropy_conf,\n",
        "            \"ci_conf\": bay_llsvi_ci_conf,\n",
        "            \"uc\": bay_llsvi_uc,\n",
        "            \"uce\": bay_llsvi_uce\n",
        "        },\n",
        "        \"Bayesian LL-Dropout\": {\n",
        "            \"accuracy\": bay_lldrop_accuracy,\n",
        "            \"auc\": bay_lldrop_auc,\n",
        "            \"binary_accuracy\": bay_lldrop_accuracy,\n",
        "            \"f1\": bay_lldrop_f1,\n",
        "            \"mae\": bay_lldrop_mae,\n",
        "            \"rmse\": bay_lldrop_rmse,\n",
        "            \"prob_conf\": bay_lldrop_prob_conf,\n",
        "            \"entropy_conf\": bay_lldrop_entropy_conf,\n",
        "            \"ci_conf\": bay_lldrop_ci_conf,\n",
        "            \"uc\": bay_lldrop_uc,\n",
        "            \"uce\": bay_lldrop_uce\n",
        "        }\n",
        "    }\n",
        "\n",
        "    # Build a patient-level summary for a selected patient from Bayesian LL-SVI results.\n",
        "    patient_idx = 0  # For example, choose the first sample\n",
        "    patient_cont_pred = bayesian_llsvi_results['continuous_predictions'][patient_idx]\n",
        "    patient_std = bayesian_llsvi_results['uncertainties'][patient_idx]\n",
        "    patient_ground_truth = det_labels[patient_idx]\n",
        "    reg_error = abs(patient_cont_pred - patient_ground_truth)\n",
        "    patient_cdf_probs = bayesian_llsvi_results['cdf_probs'][patient_idx]\n",
        "    patient_four_class_label = bayesian_llsvi_results['four_class_predictions'][patient_idx]\n",
        "    patient_binary_label = bayesian_llsvi_results['binary_predictions'][patient_idx]\n",
        "    patient_prob_conf = np.max(patient_cdf_probs)\n",
        "    patient_entropy_conf = np.mean(entropy_confidence(np.expand_dims(patient_cdf_probs, axis=0)))\n",
        "    patient_ci_conf = np.mean(ci_confidence(np.array([patient_std])))\n",
        "    patient_uc = np.mean(uncertainty_degree(np.expand_dims(patient_cdf_probs, axis=0)))\n",
        "    patient_uce, _ = calculate_uce(np.array([patient_ground_truth]), np.array([patient_cont_pred]), np.array([patient_std]))\n",
        "\n",
        "    patient_summary = {\n",
        "        \"patient_id\": \"Patient 042\",\n",
        "        \"predicted_score\": patient_cont_pred,\n",
        "        \"std\": patient_std,\n",
        "        \"ground_truth\": patient_ground_truth,\n",
        "        \"reg_error\": reg_error,\n",
        "        \"cdf_probs\": patient_cdf_probs.tolist() if isinstance(patient_cdf_probs, np.ndarray) else patient_cdf_probs,\n",
        "        \"four_class_label\": patient_four_class_label,\n",
        "        \"binary_label\": patient_binary_label,\n",
        "        \"prob_conf\": patient_prob_conf,\n",
        "        \"entropy_conf\": patient_entropy_conf,\n",
        "        \"ci_conf\": patient_ci_conf,\n",
        "        \"uc\": patient_uc,\n",
        "        \"uce\": patient_uce\n",
        "    }\n",
        "\n",
        "    from utils.reporting import generate_clinical_report\n",
        "    generate_clinical_report(overall_metrics, patient_summary, output_dir='output', filename='clinical_report.txt')\n",
        "    logging.info(\"Clinical report generated and saved to output/clinical_report.txt\")\n",
        "\n",
        "    from utils.plotting import plot_regression_uncertainty\n",
        "    if bayesian_llsvi_results.get('continuous_predictions') is not None and bayesian_llsvi_results.get('uncertainties') is not None:\n",
        "        plot_regression_uncertainty(\n",
        "            np.array(bayesian_llsvi_results['continuous_predictions']),\n",
        "            np.array(bayesian_llsvi_results['uncertainties']),\n",
        "            np.array(det_labels)\n",
        "        )\n",
        "    logging.info(\"Pipeline execution completed.\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "iqdlfr8UTEJd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd17d0c1-eccf-4e29-c67e-d699418b6f9c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/densenet121-a639ec97.pth\" to /root/.cache/torch/hub/checkpoints/densenet121-a639ec97.pth\n",
            "100%|██████████| 30.8M/30.8M [00:00<00:00, 196MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing keys: []\n",
            "Unexpected keys: []\n",
            "Missing keys: []\n",
            "Unexpected keys: []\n"
          ]
        }
      ]
    }
  ]
}