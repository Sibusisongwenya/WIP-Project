{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMu7FbQ3ule7nk4/kN2WAsc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sibusisongwenya/WIP-Project/blob/main/plotting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A2Bmgkrv-RNW"
      },
      "outputs": [],
      "source": [
        "# utils/plotting.py\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "import itertools\n",
        "import logging\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.calibration import calibration_curve\n",
        "from scipy.stats import linregress\n",
        "\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "\n",
        "def ensure_directory_exists(directory: str) -> None:\n",
        "    try:\n",
        "        os.makedirs(directory, exist_ok=True)\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Failed to create directory '{directory}': {e}\")\n",
        "        raise\n",
        "\n",
        "def save_figure(output_dir: str, filename: str) -> None:\n",
        "    output_dir_path = Path(output_dir)\n",
        "    ensure_directory_exists(output_dir)\n",
        "    filepath = output_dir_path / filename\n",
        "    try:\n",
        "        plt.savefig(filepath)\n",
        "        logging.info(f\"Saved plot to {filepath}\")\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Failed to save plot {filepath}: {e}\")\n",
        "    finally:\n",
        "        plt.close()\n",
        "\n",
        "def plot_regression_uncertainty(means: np.ndarray, stds: np.ndarray, ground_truth: np.ndarray,\n",
        "                                output_dir: str = 'output', filename: str = 'regression_uncertainty.png') -> None:\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sorted_idx = np.argsort(means)\n",
        "    sorted_means = means[sorted_idx]\n",
        "    sorted_stds = stds[sorted_idx]\n",
        "    sorted_truth = ground_truth[sorted_idx]\n",
        "\n",
        "    plt.errorbar(np.arange(len(sorted_means)), sorted_means, yerr=sorted_stds,\n",
        "                 fmt='o', alpha=0.7, label='Prediction Â± STD')\n",
        "    plt.scatter(np.arange(len(sorted_truth)), sorted_truth, color='red', label='Ground Truth')\n",
        "    plt.title(\"Regression Predictions with Uncertainty\")\n",
        "    plt.xlabel(\"Samples (sorted by prediction)\")\n",
        "    plt.ylabel(\"Mayo Score\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    save_figure(output_dir, filename)\n",
        "\n",
        "def plot_calibration_histograms(probs: np.ndarray, labels: np.ndarray, probability_method: str, n_bins: int = 10, output_dir: str = 'output') -> None:\n",
        "    if probs.ndim != 2:\n",
        "        raise ValueError(\"`probs` must be a 2D array.\")\n",
        "    if labels.ndim != 1:\n",
        "        raise ValueError(\"`labels` must be a 1D array.\")\n",
        "    if len(probs) != len(labels):\n",
        "        raise ValueError(\"Number of samples in `probs` and `labels` must match.\")\n",
        "\n",
        "    ensure_directory_exists(output_dir)\n",
        "    num_classes = probs.shape[1]\n",
        "    for class_index in range(num_classes):\n",
        "        class_probs = probs[:, class_index]\n",
        "        correct_preds = class_probs[labels == class_index]\n",
        "        incorrect_preds = class_probs[labels != class_index]\n",
        "\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        bins = np.histogram_bin_edges(class_probs, bins=n_bins)\n",
        "        plt.hist(correct_preds, bins=bins, alpha=0.7, label='Correct Predictions', color='blue')\n",
        "        plt.hist(incorrect_preds, bins=bins, alpha=0.7, label='Incorrect Predictions', color='red')\n",
        "        plt.xlabel(f'Predicted Probability (Class {class_index})', fontsize=12)\n",
        "        plt.ylabel('Frequency', fontsize=12)\n",
        "        plt.title(f'Calibration Histogram for Class {class_index} ({probability_method.upper()})', fontsize=14)\n",
        "        plt.legend(loc='upper center')\n",
        "        plt.grid(True, linestyle='--', alpha=0.5)\n",
        "        plt.tight_layout()\n",
        "        save_figure(output_dir, f'calibration_histogram_class_{class_index}_{probability_method}.png')\n",
        "\n",
        "def plot_uncertainty_histogram(uncertainties: np.ndarray, model_name: str, probability_method: str, output_dir: str = 'output') -> None:\n",
        "    ensure_directory_exists(output_dir)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.hist(uncertainties, bins=30, alpha=0.7, color='purple')\n",
        "    plt.xlabel('Uncertainty (Std. Dev.)', fontsize=12)\n",
        "    plt.ylabel('Frequency', fontsize=12)\n",
        "    plt.title(f'Uncertainty Histogram - {model_name} ({probability_method.upper()})', fontsize=14)\n",
        "    plt.grid(True, linestyle='--', alpha=0.5)\n",
        "    plt.tight_layout()\n",
        "    save_figure(output_dir, f'uncertainty_histogram_{model_name}_{probability_method}.png')\n",
        "\n",
        "def plot_uncertainty_vs_error(uncertainties: np.ndarray, correct_predictions: np.ndarray, model_name: str, probability_method: str, output_dir: str = 'output') -> None:\n",
        "    ensure_directory_exists(output_dir)\n",
        "    correct_predictions = np.array(correct_predictions, dtype=bool)\n",
        "    error_rate = 1 - correct_predictions.astype(float)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.scatter(uncertainties, error_rate, alpha=0.5, color='navy')\n",
        "    slope, intercept, _, _, _ = linregress(uncertainties, error_rate)\n",
        "    regression_line = slope * uncertainties + intercept\n",
        "    plt.plot(uncertainties, regression_line, color=\"red\", label=\"Regression Line\")\n",
        "    plt.xlabel('Uncertainty (Std. Dev.)', fontsize=12)\n",
        "    plt.ylabel('Error Rate (1 - Accuracy)', fontsize=12)\n",
        "    plt.title(f'Uncertainty vs. Error Rate - {model_name} ({probability_method.upper()})', fontsize=14)\n",
        "    plt.legend()\n",
        "    plt.grid(True, linestyle='--', alpha=0.5)\n",
        "    plt.tight_layout()\n",
        "    save_figure(output_dir, f'uncertainty_vs_error_{model_name}_{probability_method}.png')\n",
        "\n",
        "def plot_confusion_matrix(cm: np.ndarray, classes: list, normalize: bool = False, title: str = 'Confusion Matrix', cmap=plt.cm.Blues, output_dir: str = 'output', filename: str = 'conf_matrix.png') -> None:\n",
        "    if not isinstance(cm, np.ndarray) or cm.shape[0] != cm.shape[1]:\n",
        "        raise ValueError(\"Confusion matrix must be a square numpy array.\")\n",
        "    ensure_directory_exists(output_dir)\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        title += \" (Normalized)\"\n",
        "    plt.figure(figsize=(8, 8))\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.0\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    plt.ylabel('True Label')\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.tight_layout()\n",
        "    save_figure(output_dir, filename)\n",
        "\n",
        "def plot_reliability_diagram(probs: np.ndarray, labels: np.ndarray, class_labels: list, n_bins: int = 10, output_dir: str = 'output', model_name: str = '') -> None:\n",
        "    if probs.ndim != 2 or labels.ndim != 1:\n",
        "        raise ValueError(\"Invalid shapes for probs or labels.\")\n",
        "    ensure_directory_exists(output_dir)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    for class_index in range(probs.shape[1]):\n",
        "        prob_true, prob_pred = calibration_curve(labels == class_index, probs[:, class_index], n_bins=n_bins)\n",
        "        plt.plot(prob_pred, prob_true, marker='.', label=f'Class {class_labels[class_index]}')\n",
        "    plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Perfect Calibration')\n",
        "    plt.xlabel('Mean Predicted Probability', fontsize=12)\n",
        "    plt.ylabel('Fraction of Positives', fontsize=12)\n",
        "    plt.title(f'Reliability Diagram{\" - \" + model_name if model_name else \"\"}', fontsize=14)\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    filename = f'reliability_diagram_{model_name if model_name else \"deterministic\"}.png'\n",
        "    save_figure(output_dir, filename)\n"
      ]
    }
  ]
}